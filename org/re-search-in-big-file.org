#+Title: regular expression search in big file

各种shell工具很好用，简单的文本处理用grep，sed，awk很方便，但是它们都有力所不及的时候。
grep可以匹配行，但无法提取行。sed可以匹配，提取，但是如果要用到跨越多行的模式，sed就不太好用了。
awk同样也是如此，对符合格式的文本，处理很方便，但是对跨越多行的模式都很难处理。

所以作为补充，我们还是需要一个能根据任意正则表达式提取文本的工具。
在实现这个工具的过程中，我们也会明白为什么这些shell工具不直接提供多行匹配的功能。

比如，用python来实现:
#+begin_src python
for i in re.findall(sys.argv[1], sys.stdin.read()):
    print ' '.join(tolist(i))
#+end_src
上面这段代码是正确的，但是有个致命的缺陷：无法处理大文件。因为它是把所有的输入都读到内存中后在去用正则表达式匹配。
所以能处理的文件大小是有限的，并且因为是先读后匹配，而不是边读边匹配，所以比较慢。

那么，最简单的一个改进方法是用mmap把文件映射到内存：
#+begin_src python
def find_all(path, pat):
    with open(path, "r") as f:
        return re.findall(pat, mmap.mmap(f.fileno(), 0, mmap.MAP_PRIVATE, mmap.PROT_READ))
#+end_src
这种方法看起来很完美，不受物理内存大小限制，并且很快。但是有个致命的缺陷: 不能处理管道和socket。

从这里我们就明白了，允许多行匹配的一个代价：不能接受管道的输入。而各种shell工具显然不能接受这种代价。

* 为什么没有针对stream的正则表达式库？
grep, sed, awk都可以针对管道做正则表达式匹配，但是本质上都局限在单行。要跨行匹配并不是不可能，但是比较麻烦。
为什么会这样呢？初步搜索了一下，发现一个可能的原因：因为没有针对stream的正则表达式库。

所有的正则表达式库都接受字符串作为参数(待确定，但是可以保险地说，几乎没有针对stream的正则表达式)，但是正则表达式匹配难道不是只遍历一遍字符串吗？匹配的过程中永远不会回退，
既然如此，为什么不能接受stream作为参数呢？

是因为没有需求吗？仔细考虑一下，这是没有道理的，因为假如可行，我们要改变的只是接口而已，谈不上多少编码的工作量。
所以一定有另外的原因。考虑只遍历一遍字符串，有什么不能做到。实际上很难想到一遍匹配有什么做不到的。即使有些特殊需求需要回退，正常的匹配确实是只需要遍历一遍字符串，

问题不是来自于匹配算法，而是来自于提取匹配串的需求，因为匹配串有可能任意长，所以如果针对stream匹配，正则表达式库就可能需要动态申请内存，
并且需要的内存不受限，更糟糕的是，由于提前不知道匹配串多长，所以不知道要准备多大的buffer，要解决这些问题大概是过于复杂了。
