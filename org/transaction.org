#+Title: transaction

只考虑MVCC的情况:
* isolation
写写冲突: 如果在事务T1开始后，有另一个事务T2修改了行R, 则如果事务T1也要修改行R，则T1与T2冲突，T1需要回滚。
T1检测到T2对行R的修改有两种情况:
1. 事务T2正在修改行R，还没有提交，T1检测到行R上已经
为什么一定要避免写写冲突？
考虑

* Questions
** 为什么Two Phrase Locking可以保证串行化?
   首先说明两阶段锁的定义，如果在某种机制的保证下，任意一个事务可以满足如下两个条件，我们就说这种并发控制机制使用了两阶段锁。
   1. 事务开始时不持有任何锁，事务结束前要释放掉所有的锁。
   2. 任意一个事务，如果开始释放锁，那就不能再申请锁。
   所以两阶段锁实施时严格分为两个阶段，第一阶段只加锁，不释放锁；第二阶段只释放锁，不能加锁。

   两阶段锁可以保证串行化隔离级别，这个结论并不是十分明显, 如何证明它呢?

我们考虑在某个时间段内开始和结束的所有事务，不考虑回滚的事务和在这个时间段以外开始和结束的事务。
接下来我们要明确可串行化究竟是什么概念。并发执行的一批事务如果是可串行化的，
那么事务的执行结果可以等价于这批事务按照某个顺序串行化地执行的结果。当然一个结果可能对应着多种不同的串行化执行顺序。
最简单的情况，两个事务T1，T2完全独立，那么它们的执行结果即可以看作 [T1,T2]串行执行的结果，也可以看作[T2,T1]串行执行的结果。
这告诉我们，在某种可串行化的并发控制的机制下，一个具体的执行过程只能给一批事务定一个偏序，而不是全序，等价于一个有向无环图。

为了证明两阶段锁可以实现串行化，我们就要构造出串行化的偏序，不妨把这个序称为"先后关系":

先考虑没有条件更新的情况，一个事务 T_i 可以表示为一个更新操作的序列:
[(c_ij, v_ij)| 0 <= i < N_i ]
其中 (c_ij, v_ij)表示要把 c_ij 修改为 v_ij.

两个事务之间的关系有以下三种可能:
1. 如果两个事务完全独立(即它们修改的单元格不相交), 那么它们没有先后关系；
2. 如果事务 T_1, T_2 会修改同样的单元格，但是没有引起写冲突, 即其中的一个事务加锁时，另一个事务已经把锁释放了,
   更精确的说法是事务T_1,T_2 执行时都不需要等待对方释放锁，那么 T_1, T_2 实际执行就有先后关系, 没有并发控制的问题；
3. 如果事务 T_1,T_2 修改的单元格有重叠，并且并发执行，那么T_1, T_2 执行时必然有一个事务等待了另一个事务,
   当然T_1,T_2 有可能死锁，这里排除死锁的情况。两阶段锁的一个重要特性是排除死锁之后, T_1, T_2 之间的等待关系是单向的，
   如果T_1 在某个时刻需要等待 T_2 释放一把锁，那么接下来，T_2 就不可能等待T_1 释放锁。
综合以上的讨论，我们猜想，事务之间的"等待关系"就定义了我们要寻找的"先后关系".
当然，首先要证明的是在没有死锁的情况下，"等待关系"确实是一种偏序，也即"等待关系"不会形成环。只要注意到，如果T1等待T2，
那么T1的第一阶段结束的时刻必须严格晚于T2的第二阶段开始的时间，如果T1，T2，T3,...,T1形成了一个环，那么我们可以得到，
T1的第一阶段结束的时刻必须严格晚于T1的第二阶段开始的时间，这是不可能的，所以"等待关系"是不会有环的。

接下来要证明的是如果T1等待T2, 那么从结果上看，确实可以等价于先执行T2，再执行T1。首先注意到，T1等待T2，这意味着
T2先执行完第一阶段，也即T2先拿到所有的锁，那么在T2开始释放锁之前，T2的修改都已经完成，并且此时T1已经开始的修改不可能和
T2冲突，因为T2此时还没有释放锁，T1不可能修改T2刚修改过的单元格，所以单看T1，T2之间的关系，可以等价于先执行T2，再执行T1。

# 不妨设，任意两次不同的更新，把单元格的值都修改为不同的值，注意这样假定不影响证明的通用性，因为对可串行化来说，
# 这是一个增强的条件，如果单元格被修改为不同的值依然可以串行化，那么有相同值的情况当然也可以按同样的顺序串行化。

# 既然考虑的是最终事务执行的结果，那么那些不影响最终结果的事务可以不予考虑，只考虑那些体现在最终结果集上的修改。
# 如果一个单元格 C_k 被事务 T_i 修改为 V_k, 那么说明事务 T_i 在串行化时应该可以排在最后，
# 当然可以排在最后的可能还有别的若干事务。
# 为了证明事务 T_i 确实可以排在最后，考虑其余的任意一个事务 T_x，如果一个 T_x 修改的单元与 T_i 不想交，
# 那么 T_x 当然可以排在 T_i 之前，如果 T_x 修改的单元格 C_x 与 T_i 重叠，那么

** 为什么按顺序加锁可以避免死锁?
这里只考虑互斥锁。一个简单的死锁的例子是:
#+begin_example
T1: lock A; lock B;
T2: lock B; lock A;
#+end_example
当T1 lock A成功，并且T2 lock B成功之后，就会出现死锁。

避免死锁的一个办法是，给所有的共享资源定一个全局的序，保证所有线程都按照同样的顺序加锁。
直观上来看，按照这个原则，上面那个简单的例子是可以避免死锁的。

但是如何证明只要保证按顺序加锁，那么任意复杂的场景都不会出现死锁呢？
我们可以考虑一下为什么会出现死锁。换个问题，出现死锁的时候有什么特征呢?
#首先死锁形成的时候，必然至少有一个线程会无限期的等待锁（假如没有别的机制检测并解除死锁的话).
首先死锁形成的时候，直观上考虑会有"环"形成, 但究竟这个"环"是指什么呢？我们需要精确定义。
"环"是指线程之间加锁的依赖关系，当然这个关系是瞬时的，如果一个线程T1需要的锁lockX被T2持有，
那么T1的继续执行就依赖于T2在未来的某个时刻把lockX释放掉。如此一来，死锁就等同于在某个时刻有若干个线程形成了依赖环。
当然要形成环至少要有一个线程(一个线程要对自己已经拿到的锁再次加锁), 但是也可以由很多个线程形成, 比如: T1依赖于T2， T2依赖于T3，T3依赖于T1。

有了上面线程依赖关系的概念，我们进一步看看为什么按顺序加锁不会出现依赖环。
对于任意一个线程T来说，记时刻t它持有的编号最高的锁是H(T,t), 那么H(T,t)就给线程定了一个序。
我们可以想象按照这个顺序把所有线程在一条线上排开, 并且，如果T1依赖于T2，必然有H(T1,t) < H(T2,t)，
也就是说只有排在前面的线程会依赖于排在后面的线程，而不会反过来，这样依赖关系便不可能形成环。


